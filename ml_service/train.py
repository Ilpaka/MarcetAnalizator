import warnings
warnings.filterwarnings('ignore')

import numpy as np
import pandas as pd
import pickle
import os
import sys
from datetime import datetime
import requests

print("üîß –ò–º–ø–æ—Ä—Ç—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã...")

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

print("üì¶ –ò–º–ø–æ—Ä—Ç–∏—Ä—É—é –º–æ–¥—É–ª–∏...")

from models.lstm_scratch import LSTM
from preprocessing.features import (
    create_features,
    StandardScaler,
    prepare_sequences
)

def download_binance_data(symbol='BTCUSDT', interval='1h', limit=1000):
    url = f"https://api.binance.com/api/v3/klines?symbol={symbol}&interval={interval}&limit={limit}"

    print(f"üì° –ó–∞–≥—Ä—É–∂–∞—é –¥–∞–Ω–Ω—ã–µ {symbol} ({interval})...")
    response = requests.get(url)

    if response.status_code != 200:
        raise Exception(f"–û—à–∏–±–∫–∞ API: {response.text}")

    klines = response.json()

    df = pd.DataFrame(klines, columns=[
        'time', 'open', 'high', 'low', 'close', 'volume',
        'close_time', 'quote_volume', 'trades', 'taker_buy_base',
        'taker_buy_quote', 'ignore'
    ])

    df['time'] = (df['time'] / 1000).astype(int)
    for col in ['open', 'high', 'low', 'close', 'volume']:
        df[col] = df[col].astype(float)

    df = df[['time', 'open', 'high', 'low', 'close', 'volume']]

    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Å–≤–µ—á–µ–π")
    return df

def train_model(symbol='BTCUSDT',
                interval='1h',
                lookback=30,
                hidden_size=32,
                num_layers=1,
                epochs=20,
                batch_size=16,
                learning_rate=0.001,
                val_split=0.2,
                progress_callback=None):
    print("\n" + "=" * 70)
    print("üöÄ –ù–ê–ß–ò–ù–ê–Æ –û–ë–£–ß–ï–ù–ò–ï LSTM –ú–û–î–ï–õ–ò")
    print("=" * 70)

    df = download_binance_data(symbol, interval, limit=1000)

    print("\nüìä Feature Engineering...")
    df_features = create_features(df)

    feature_cols = [col for col in df_features.columns
                   if col not in ['time', 'close'] and 'lag' not in col]

    print(f"üìå –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è {len(feature_cols)} —Ñ–∏—á–µ–π")

    print("\nüîß –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")

    scaler = StandardScaler()
    X_data = scaler.fit_transform(df_features[feature_cols].values)

    close_scaler = StandardScaler()
    close_values = df_features['close'].values.reshape(-1, 1)
    close_scaler.fit(close_values)

    close_normalized = close_scaler.transform(close_values).flatten()
    X_data = np.column_stack([close_normalized, X_data])

    X, y = prepare_sequences(X_data, target_col_idx=0,
                            lookback=lookback, forecast_horizon=1)

    split_idx = int(len(X) * (1 - val_split))
    X_train, X_val = X[:split_idx], X[split_idx:]
    y_train, y_val = y[:split_idx], y[split_idx:]

    print(f"üì¶ Train: {X_train.shape}, Val: {X_val.shape}")

    print("\nüß† –°–æ–∑–¥–∞–Ω–∏–µ LSTM –º–æ–¥–µ–ª–∏...")
    input_size = X_train.shape[2]
    output_size = 1

    model = LSTM(
        input_size=input_size,
        hidden_size=hidden_size,
        output_size=output_size,
        num_layers=num_layers,
        learning_rate=learning_rate
    )

    print("\nüèãÔ∏è –ù–∞—á–∏–Ω–∞—é –æ–±—É—á–µ–Ω–∏–µ...")
    print(f"Epochs: {epochs}, Batch size: {batch_size}")
    print("-" * 70)

    train_losses = []
    val_losses = []
    best_val_loss = float('inf')
    patience_counter = 0
    patience = 5

    for epoch in range(epochs):
        epoch_losses = []

        n_batches = len(X_train) // batch_size

        for batch_idx in range(n_batches):
            start_idx = batch_idx * batch_size
            end_idx = start_idx + batch_size

            X_batch = X_train[start_idx:end_idx]
            y_batch = y_train[start_idx:end_idx]

            loss, _ = model.train_step(X_batch, y_batch)
            epoch_losses.append(loss)

        avg_train_loss = np.mean(epoch_losses)
        train_losses.append(avg_train_loss)

        y_val_pred = model.predict(X_val)
        val_loss = np.mean((y_val - y_val_pred) ** 2)
        val_losses.append(val_loss)

        print(f"Epoch {epoch + 1}/{epochs} | "
              f"Train Loss: {avg_train_loss:.6f} | "
              f"Val Loss: {val_loss:.6f}")

        # Call progress callback if provided
        if progress_callback:
            try:
                progress_callback({
                    'epoch': epoch + 1,
                    'train_loss': float(avg_train_loss),
                    'val_loss': float(val_loss),
                    'completed': False
                })
            except Exception as e:
                print(f"Warning: Progress callback failed: {e}")

        if val_loss < best_val_loss:
            best_val_loss = val_loss
            patience_counter = 0
            print(f"  ‚úÖ –ù–æ–≤–∞—è –ª—É—á—à–∞—è –º–æ–¥–µ–ª—å!")
        else:
            patience_counter += 1
            if patience_counter >= patience:
                print(f"\n‚ö†Ô∏è Early stopping –Ω–∞ epoch {epoch + 1}")
                if progress_callback:
                    try:
                        progress_callback({
                            'epoch': epoch + 1,
                            'train_loss': float(avg_train_loss),
                            'val_loss': float(val_loss),
                            'completed': True,
                            'message': f'Early stopping at epoch {epoch + 1}'
                        })
                    except:
                        pass
                break

    print("\n" + "=" * 70)
    print("‚úÖ –û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û!")
    print("=" * 70)
    
    # Final progress callback
    if progress_callback:
        try:
            progress_callback({
                'epoch': epochs,
                'train_loss': float(train_losses[-1]) if train_losses else 0.0,
                'val_loss': float(val_losses[-1]) if val_losses else 0.0,
                'completed': True,
                'message': 'Training completed successfully'
            })
        except:
            pass

    print("\nüìà –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–º —Å–µ—Ç–µ...")

    y_val_pred = model.predict(X_val)

    y_val_real = close_scaler.inverse_transform(y_val)
    y_val_pred_real = close_scaler.inverse_transform(y_val_pred.reshape(-1, 1))

    mae = np.mean(np.abs(y_val_real - y_val_pred_real))
    rmse = np.sqrt(np.mean((y_val_real - y_val_pred_real) ** 2))
    mape = np.mean(np.abs((y_val_real - y_val_pred_real) / (y_val_real + 1e-8))) * 100

    print(f"MAE:  ${mae:.2f}")
    print(f"RMSE: ${rmse:.2f}")
    print(f"MAPE: {mape:.2f}%")

    y_val_direction = np.sign(np.diff(y_val_real.flatten()))
    y_pred_direction = np.sign(np.diff(y_val_pred_real.flatten()))
    direction_accuracy = np.mean(y_val_direction == y_pred_direction) * 100

    print(f"Direction Accuracy: {direction_accuracy:.2f}%")

    print("\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")

    os.makedirs('models', exist_ok=True)
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    model_dir = f'models/{symbol}_{interval}_{timestamp}'
    os.makedirs(model_dir, exist_ok=True)

    model_path = os.path.join(model_dir, 'lstm_model.pkl')
    with open(model_path, 'wb') as f:
        pickle.dump(model, f)

    import time
    metadata = {
        'scaler': scaler,
        'close_scaler': close_scaler,
        'feature_cols': feature_cols,
        'lookback': lookback,
        'input_size': input_size,
        'hidden_size': hidden_size,
        'num_layers': num_layers,
        'symbol': symbol,
        'interval': interval,
        'mae': float(mae),
        'rmse': float(rmse),
        'mape': float(mape),
        'direction_accuracy': float(direction_accuracy),
        'train_losses': train_losses,
        'val_losses': val_losses,
        'trained_at': int(time.time() * 1000),
        'model_path': model_dir,
    }

    metadata_path = os.path.join(model_dir, 'metadata.pkl')
    with open(metadata_path, 'wb') as f:
        pickle.dump(metadata, f)

    print(f"‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {model_dir}")

    return model, metadata

if __name__ == '__main__':
    print("\n" + "=" * 70)
    print("üéØ CRYPTO ML TRAINER - LSTM from Scratch")
    print("=" * 70)

    model, metadata = train_model(
        symbol='BTCUSDT',
        interval='1m',
        lookback=60,
        hidden_size=64,
        num_layers=2,
        epochs=30,
        batch_size=32,
        learning_rate=0.001,
        val_split=0.2
    )

    print("\n" + "=" * 70)
    print("üéâ –í–°–Å –ì–û–¢–û–í–û! –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫ ML —Å–µ—Ä–≤–∏—Å–∞:")
    print("   cd ml-service")
    print("   python -m app.main")
    print("=" * 70)
